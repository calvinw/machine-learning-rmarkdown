---
title: "Hot Choc"
jupyter:
  kernelspec:
    display_name: R
    language: R
    name: ir
---

```{r echo=T, results='hide', message=F, warning=F}
options("scipen"=100, "digits"=4)
if(!require("rpart")) install.packages("rpart")
if(!require("rpart.plot")) install.packages("rpart.plot")
if(!require("Metrics")) install.packages("Metrics")
library("rpart")
library("rpart.plot")
library("Metrics")
```

```{r include=F}
ex<-T
```

## Training Data

First lets take a look at the data we will work with. Suppose we have the following weather data and want to predict when someone will buy hot chocolate given the weather conditions. For example will someone buy hot chocolate when the it is humid or windy?

So here is the data we have, this will be our training data:

- `Buys` is our result or outcome
- `Humid`, `Windy` are the predictors

We hope that some of these predictors will help up predict the `Buys` column:   
So we will use this data to build our model. Then after we build the model, we will test it using some different data, called the "testing" data. Once we test it we will be able to deterimine how accurate our model is.

To start we read the training data above from a csv file and print out its structore:

```{r}
trainurl<-"https://docs.google.com/spreadsheets/d/e/2PACX-1vQuCBiuFmkNVmiG_0iXURTsvBytLIxOYhiWEIxwOwGUKltTwB0aVP-ZbdPPN6luekXca9gzz2XCADS0/pub?gid=0&single=true&output=csv"
train<-read.csv(trainurl)
```

 - Print out the info of the data frame using `str(train)`
```{r include=ex, eval=F}
CODE
```
```{r include=!ex}
str(train)
```

Now let's print out the training set to make sure we read it correctly:

- Print out the the data frame using `print(train)`
```{r include=ex, eval=F}
CODE
```
```{r include=!ex}
print(train)
```

## Testing Data 

Next let's look at some data that we can use as a testing set. This data we will use to evaluate how well the models we looked at above will do when they see "new" data. This gives a better idea of how accurate our model is.

First we read the test set and look at its structure:

```{r}
testurl<-"https://docs.google.com/spreadsheets/d/e/2PACX-1vQuCBiuFmkNVmiG_0iXURTsvBytLIxOYhiWEIxwOwGUKltTwB0aVP-ZbdPPN6luekXca9gzz2XCADS0/pub?gid=572053114&single=true&output=csv"
test<-read.csv(testurl)
```

 - Print out the info of this data frame using `str(test)`
```{r include=ex, eval=F}
CODE
```
```{r include=!ex}
str(test)
```

And now print out the test set:

- Print out the the data frame using `print(test)`
```{r include=ex, eval=F}
CODE
```
```{r include=!ex}
print(test)
```

We will try to understand how to build up a decision tree for this example by just using one variable at a time to model the decision tree. 

### Model 1 - Split on Humid 

#### Training

What about if we use just `Humid` to try to predict `Buys`.

- sort the data frame using `Humid`
```{r}
print(train[order(train$Humid),])
```

- Put in the right model for modeling `Buys` based just on `Humid` 
```{r include=ex, eval=F}
control = rpart.control(minsplit=1,maxdepth=1)
model <- rpart(CODE, data=train, method="class", control = control)
rpart.plot(model, type=4, extra = 1, digits=-2)
```
```{r include=!ex}
control = rpart.control(minsplit=1,maxdepth=1)
model <- rpart(Buys~Humid, data=train, method="class", control = control)
rpart.plot(model, type=4, extra = 1, digits=-2)
```

#### Testing

Here are the predictions for our test data:

- Make predictions and create a dataframe by running the code below:
```{r, eval=!ex}
pred <- predict(model, newdata = test, type = 'class')
compare <- data.frame(actual=test$Buys, predictions=pred)
print(compare)
```

Here is the confusion matrix:

- Create the confusion matrix by passing `test$Buys` and `pred` to the `table` function:
```{r include=ex, eval=F}
CODE
```
```{r include=!ex, eval=!ex}
table(test$Buys, pred)
```

Here is the accuracy:

- calculate the accuracy passing `test$Buys` and `pred` to the `accuracy` function:
```{r include=ex, eval=F}
CODE
```
```{r include=!ex, eval=!ex}
accuracy(test$Buys, pred)
```


### Model 2 - Split on Windy 

#### Training

Finally what about if we use `Windy` to try to predict `Buys`:

- sort the data frame using `Windy`
```{r}
print(train[order(train$Windy),])
```

- Put in the right model for modeling `Buys` based just on `Windy` 
```{r include=ex, eval=F}
control = rpart.control(minsplit=1,maxdepth=1, cp=-1)
model <- rpart(CODE, data=train, method="class", control = control)
rpart.plot(model, type=4, extra = 1, digits=-2)
```
```{r include=!ex, eval=!ex}
control = rpart.control(minsplit=1,maxdepth=1, cp=-1)
model <- rpart(Buys~Windy, data=train, method="class", control = control)
rpart.plot(model, type=4, extra = 1, digits=-2)
```

#### Testing

Here are the predictions for our test data:

- Make predictions and create a dataframe by running the code below:
```{r include=!ex, eval=!ex}
pred <- predict(model, newdata = test, type = 'class')
compare <- data.frame(actual=test$Buys, predictions=pred)
print(compare)
```

Here is the confusion matrix:

- Create the confusion matrix by passing `test$Buys` and `pred` to the `table` function:
```{r include=ex, eval=F}
CODE
```
```{r include=!ex, eval=!ex}
table(test$Buys, pred)
```

Here is the accuracy:


- calculate the accuracy passing `test$Buys` and `pred` to the `accuracy` function:
```{r include=ex, eval=F}
CODE
```
```{r include=!ex, eval=!ex}
accuracy(test$Buys, pred)
```

### Model 3 - All the predictors 

#### Training

Here is a model that uses all the predictors:

- Put in the right model for modeling `Buys` based just on `Windy` and `Humid` 
```{r include=ex, eval=F}
control = rpart.control(minsplit=1, maxdepth=3, cp=-1)
model <- rpart(CODE, data=train, method="class", control = control)
rpart.plot(model, type=4, extra = 1, digits=-2)
```
```{r include=!ex, eval=!ex}
control = rpart.control(minsplit=1, maxdepth=3, cp=-1)
model <- rpart(Buys~Windy+Humid, data=train, method="class", control = control)
rpart.plot(model, type=4, extra = 1, digits=-2)
```

#### Testing

Here are the predictions for our test data:

- Make predictions and create a dataframe by running the code below:
```{r, eval=!ex}
pred <- predict(model, newdata = test, type = 'class')
compare <- data.frame(actual=test$Buys, predictions=pred)
print(compare)
```

Here is the confusion matrix:

- Create the confusion matrix by passing `test$Buys` and `pred` to the `table` function:
```{r include=ex, eval=F}
CODE
```
```{r include=!ex, eval=!ex}
table(test$Buys, pred)
```

Here is the accuracy:

- calculate the accuracy passing `test$Buys` and `pred` to the `accuracy` function:
```{r include=ex, eval=F}
CODE
```
```{r include=!ex, eval=!ex}
accuracy(test$Buys, pred)
```

