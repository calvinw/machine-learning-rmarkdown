{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Accuracy"
      ],
      "id": "5ead5fff-dd24-40f3-acb1-f9611062c784"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (!require(\"Metrics\")) install.packages(\"Metrics\")\n",
        "library(\"Metrics\")"
      ],
      "id": "1e994081-a89b-485a-af78-ed868cff0f29"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating Models\n",
        "\n",
        "### Model 1\n",
        "\n",
        "Suppose we have created a model 1 and made some predictions.\n",
        "\n",
        "Here are the actuals from some data and predicted for for that same\n",
        "data:\n",
        "\n",
        "#### Model 1 predictions vs actuals\n",
        "\n",
        "| actuals | predicted |\n",
        "|---------|-----------|\n",
        "| yes     | yes       |\n",
        "| yes     | no        |\n",
        "| yes     | yes       |\n",
        "| yes     | yes       |\n",
        "| no      | yes       |\n",
        "| no      | no        |\n",
        "| no      | yes       |\n",
        "| yes     | no        |\n",
        "| no      | yes       |\n",
        "| yes     | yes       |\n",
        "| yes     | yes       |\n",
        "\n",
        "-   create two vectors called `actuals` and `predicted` with the data\n",
        "    above.\n",
        "-   create a dataframe called `df` that has these columns\n",
        "-   print out the dataframe with `print(df)`"
      ],
      "id": "b88d09cc-25df-49c5-9cc3-dc28d882ce1e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "actuals   <- CODE \n",
        "predicted   <- CODE \n",
        "df<- data.frame(actuals, predicted)\n",
        "print(df)"
      ],
      "id": "376bb02b-5b0c-4e26-a7f3-19cc86053cf9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   actuals predicted\n",
            "1      yes       yes\n",
            "2      yes        no\n",
            "3      yes       yes\n",
            "4      yes       yes\n",
            "5       no       yes\n",
            "6       no        no\n",
            "7       no       yes\n",
            "8      yes        no\n",
            "9       no       yes\n",
            "10     yes       yes\n",
            "11     yes       yes"
          ]
        }
      ],
      "source": [
        "actuals<-c('yes','yes','yes','yes','no','no','no','yes','no','yes', 'yes')\n",
        "predicted<-c('yes','no','yes','yes','yes','no','yes','no','yes','yes', 'yes')\n",
        "df<- data.frame(actuals, predicted)\n",
        "print(df)"
      ],
      "id": "97e66c85-3a3c-489d-a6be-65d429413fc6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 1 Accuracy\n",
        "\n",
        "-   Find the accuracy by using `accuracy(actuals, predicted)`"
      ],
      "id": "894152a5-22f7-48e0-b70b-daeb07272c37"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "47b59b16-c33c-44cd-9ed2-93494a2a8ca5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 0.5454545"
          ]
        }
      ],
      "source": [
        "accuracy(actuals, predicted)"
      ],
      "id": "d25c46f5-8beb-4858-9675-4378bedbaa46"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy is ???\n",
        "\n",
        "### Model 1 Confusion Matrix\n",
        "\n",
        "Remember:\n",
        "\n",
        "|            |            | **Predicted** |            |\n",
        "|------------|------------|---------------|------------|\n",
        "|            |            | *Negative*    | *Positive* |\n",
        "| **Actual** | *Negative* | TN            | FP         |\n",
        "|            | *Positive* | FN            | TP         |\n",
        "\n",
        "-   Find the confusion matrix using `table(actuals, predicted)`"
      ],
      "id": "bc1c1c78-668d-4935-adaa-c49e8c0a6890"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "818eb8ff-212e-4f7b-8b2f-366d022c1118"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       predicted\n",
            "actuals no yes\n",
            "    no   1   3\n",
            "    yes  2   5"
          ]
        }
      ],
      "source": [
        "table(actuals, predicted)"
      ],
      "id": "bd9e120f-6cb2-431c-b2e5-9f25b96f2472"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   $TP$ is ???\n",
        "-   $FP$ is ???\n",
        "-   $TN$ is ???\n",
        "-   $FN$ is ???\n",
        "\n",
        "### Model 2\n",
        "\n",
        "#### Model 2 predictions vs actuals\n",
        "\n",
        "| actuals | predicted |\n",
        "|---------|-----------|\n",
        "| yes     | no        |\n",
        "| yes     | no        |\n",
        "| yes     | yes       |\n",
        "| yes     | no        |\n",
        "| no      | no        |\n",
        "| no      | yes       |\n",
        "| no      | no        |\n",
        "| yes     | yes       |\n",
        "| no      | no        |\n",
        "| yes     | yes       |\n",
        "| yes     | yes       |\n",
        "\n",
        "-   create two vectors called `actuals` and `predicted` with the data\n",
        "    above.\n",
        "-   create a dataframe called `df` that has these columns\n",
        "-   print out the dataframe with `print(df)`"
      ],
      "id": "af91ed28-b82b-4e03-8181-19f12d3275d2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "411aa3d3-cefe-4615-9d95-950121ee77e4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   actuals predicted\n",
            "1      yes        no\n",
            "2      yes        no\n",
            "3      yes       yes\n",
            "4      yes        no\n",
            "5       no        no\n",
            "6       no       yes\n",
            "7       no        no\n",
            "8      yes       yes\n",
            "9       no        no\n",
            "10     yes       yes\n",
            "11     yes       yes"
          ]
        }
      ],
      "source": [
        "actuals<-c('yes','yes','yes','yes','no','no','no','yes','no','yes','yes')\n",
        "predicted<-c('no','no','yes','no','no','yes','no','yes','no','yes','yes')\n",
        "df<- data.frame(actuals, predicted)\n",
        "df"
      ],
      "id": "637dc8db-2f1d-42e8-9c8b-f49b879ba156"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 2 Accuracy\n",
        "\n",
        "-   Find the accuracy by using `accuracy(actuals, predicted)`"
      ],
      "id": "a0c27107-8ff7-48f7-af50-9dbde2b55eb1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "c599ac6c-b99c-46b5-ad13-71b506ad499d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 0.6363636"
          ]
        }
      ],
      "source": [
        "accuracy(actuals, predicted)"
      ],
      "id": "e0c8e296-4e47-4057-8b95-f0b4888c2a27"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy is ???\n",
        "\n",
        "### Model 2 Confusion Matrix\n",
        "\n",
        "Remember:\n",
        "\n",
        "|            |            | **Predicted** |            |\n",
        "|------------|------------|---------------|------------|\n",
        "|            |            | *Negative*    | *Positive* |\n",
        "| **Actual** | *Negative* | TN            | FP         |\n",
        "|            | *Positive* | FN            | TP         |\n",
        "\n",
        "-   Find the confusion matrix using `table(actuals, predicted)`"
      ],
      "id": "a81df065-9337-453b-b190-568cc8944f35"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "64d59842-3402-43a3-98c9-984c1993443c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       predicted\n",
            "actuals no yes\n",
            "    no   3   1\n",
            "    yes  3   4"
          ]
        }
      ],
      "source": [
        "table(actuals, predicted)"
      ],
      "id": "8e6c66ac-b5d5-4fe1-bcbd-afd4164372e9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   $TP$ is ???\n",
        "-   $FP$ is ???\n",
        "-   $TN$ is ???\n",
        "-   $FN$ is ???\n",
        "\n",
        "## Model 1 or Model 2\n",
        "\n",
        "Which model (Model 1 or Model 2) had the highest accuracy: ???\n",
        "\n",
        "Which model had the most false positives? ???\n",
        "\n",
        "Which model had the most false negatives? ???"
      ],
      "id": "ca455bab-38ec-45ad-8c04-67e258994b5a"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "ir",
      "display_name": "R",
      "language": "R"
    }
  }
}