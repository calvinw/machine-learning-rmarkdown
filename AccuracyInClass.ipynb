{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Accuracy"
      ],
      "id": "0f3a99f3-c4ab-423e-a287-53de04c0585e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (!require(\"Metrics\")) install.packages(\"Metrics\")\n",
        "library(\"Metrics\")"
      ],
      "id": "ef603c73-253b-4516-a70b-9f08206449bd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating Models\n",
        "\n",
        "### Model 1\n",
        "\n",
        "Suppose we have created a model 1 and made some predictions.\n",
        "\n",
        "Here are the actuals from some data and predicted for for that same\n",
        "data:\n",
        "\n",
        "#### Model 1 predictions vs actuals\n",
        "\n",
        "| actuals | predicted |\n",
        "|---------|-----------|\n",
        "| yes     | yes       |\n",
        "| yes     | no        |\n",
        "| yes     | yes       |\n",
        "| yes     | yes       |\n",
        "| no      | yes       |\n",
        "| no      | no        |\n",
        "| no      | yes       |\n",
        "| yes     | no        |\n",
        "| no      | yes       |\n",
        "| yes     | yes       |\n",
        "| yes     | yes       |\n",
        "\n",
        "-   create two vectors called `actuals` and `predicted` with the data\n",
        "    above.\n",
        "-   create a dataframe called `df` that has these columns\n",
        "-   print out the dataframe with `print(df)`"
      ],
      "id": "d66bb9a8-17c8-436d-9d93-2f69c274af3c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "actuals   <- CODE \n",
        "predicted   <- CODE \n",
        "df<- data.frame(actuals, predicted)\n",
        "print(df)"
      ],
      "id": "299a41d7-d292-401c-bc31-be967fc9c11d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   actuals predicted\n",
            "1      yes       yes\n",
            "2      yes        no\n",
            "3      yes       yes\n",
            "4      yes       yes\n",
            "5       no       yes\n",
            "6       no        no\n",
            "7       no       yes\n",
            "8      yes        no\n",
            "9       no       yes\n",
            "10     yes       yes\n",
            "11     yes       yes"
          ]
        }
      ],
      "source": [
        "actuals<-c('yes','yes','yes','yes','no','no','no','yes','no','yes', 'yes')\n",
        "predicted<-c('yes','no','yes','yes','yes','no','yes','no','yes','yes', 'yes')\n",
        "df<- data.frame(actuals, predicted)\n",
        "print(df)"
      ],
      "id": "5ce390ba-23bc-49c2-aac8-9aaca450c3f4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 1 Accuracy\n",
        "\n",
        "-   Find the accuracy by using `accuracy(actuals, predicted)`"
      ],
      "id": "82919379-7483-46de-a66d-e65dee8a288d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "2eba2e78-0035-4e55-a0fc-87d0c21c8cda"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 0.5454545"
          ]
        }
      ],
      "source": [
        "accuracy(actuals, predicted)"
      ],
      "id": "b5fc3b20-5054-4df1-b61c-6794ef89f8ce"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy is ???\n",
        "\n",
        "### Model 1 Confusion Matrix\n",
        "\n",
        "Remember:\n",
        "\n",
        "|            |            | **Predicted** |            |\n",
        "|------------|------------|---------------|------------|\n",
        "|            |            | *Negative*    | *Positive* |\n",
        "| **Actual** | *Negative* | TN            | FP         |\n",
        "|            | *Positive* | FN            | TP         |\n",
        "\n",
        "-   Find the confusion matrix using `table(actuals, predicted)`"
      ],
      "id": "d9fe0dff-22d8-4622-a8a7-dfe001c666a9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "c1dd8027-a922-4aae-a165-995555ebe4ac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       predicted\n",
            "actuals no yes\n",
            "    no   1   3\n",
            "    yes  2   5"
          ]
        }
      ],
      "source": [
        "table(actuals, predicted)"
      ],
      "id": "10f3f1a7-ada6-4b7a-9ed6-459271e3b6d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   $TP$ is ???\n",
        "-   $FP$ is ???\n",
        "-   $TN$ is ???\n",
        "-   $FN$ is ???\n",
        "\n",
        "### Model 2\n",
        "\n",
        "#### Model 2 predictions vs actuals\n",
        "\n",
        "| actuals | predicted |\n",
        "|---------|-----------|\n",
        "| yes     | no        |\n",
        "| yes     | no        |\n",
        "| yes     | yes       |\n",
        "| yes     | no        |\n",
        "| no      | no        |\n",
        "| no      | yes       |\n",
        "| no      | no        |\n",
        "| yes     | yes       |\n",
        "| no      | no        |\n",
        "| yes     | yes       |\n",
        "| yes     | yes       |\n",
        "\n",
        "-   create two vectors called `actuals` and `predicted` with the data\n",
        "    above.\n",
        "-   create a dataframe called `df` that has these columns\n",
        "-   print out the dataframe with `print(df)`"
      ],
      "id": "8af7c774-1c71-468b-9d8f-55b36511a119"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "e2611b9b-6b25-4903-88c7-79c1d4a68103"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   actuals predicted\n",
            "1      yes        no\n",
            "2      yes        no\n",
            "3      yes       yes\n",
            "4      yes        no\n",
            "5       no        no\n",
            "6       no       yes\n",
            "7       no        no\n",
            "8      yes       yes\n",
            "9       no        no\n",
            "10     yes       yes\n",
            "11     yes       yes"
          ]
        }
      ],
      "source": [
        "actuals<-c('yes','yes','yes','yes','no','no','no','yes','no','yes','yes')\n",
        "predicted<-c('no','no','yes','no','no','yes','no','yes','no','yes','yes')\n",
        "df<- data.frame(actuals, predicted)\n",
        "df"
      ],
      "id": "e866f79d-3b45-429b-a04e-1a5592f3dda0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 2 Accuracy\n",
        "\n",
        "-   Find the accuracy by using `accuracy(actuals, predicted)`"
      ],
      "id": "c1569d80-5f95-416e-bc17-1d27900116e6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "d8c1493f-5dcd-4c65-8a22-a9783e7469e8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 0.6363636"
          ]
        }
      ],
      "source": [
        "accuracy(actuals, predicted)"
      ],
      "id": "96d6cc57-b303-4a1f-b9bc-55b33d920af9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Accuracy is ???\n",
        "\n",
        "### Model 2 Confusion Matrix\n",
        "\n",
        "Remember:\n",
        "\n",
        "|            |            | **Predicted** |            |\n",
        "|------------|------------|---------------|------------|\n",
        "|            |            | *Negative*    | *Positive* |\n",
        "| **Actual** | *Negative* | TN            | FP         |\n",
        "|            | *Positive* | FN            | TP         |\n",
        "\n",
        "-   Find the confusion matrix using `table(actuals, predicted)`"
      ],
      "id": "ca7253a6-f1b6-4ec6-ba4b-27cce810f0f0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CODE"
      ],
      "id": "7c07b473-31fd-4d4b-afd9-2533d5b0b834"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       predicted\n",
            "actuals no yes\n",
            "    no   3   1\n",
            "    yes  3   4"
          ]
        }
      ],
      "source": [
        "table(actuals, predicted)"
      ],
      "id": "ca4033ba-0800-4c28-933e-6520bd1ab8c3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   $TP$ is ???\n",
        "-   $FP$ is ???\n",
        "-   $TN$ is ???\n",
        "-   $FN$ is ???\n",
        "\n",
        "## Model 1 or Model 2\n",
        "\n",
        "Which model (Model 1 or Model 2) had the highest accuracy: ???\n",
        "\n",
        "Which model had the most false positives? ???\n",
        "\n",
        "Which model had the most false negatives? ???"
      ],
      "id": "d1c9ccdc-3bb7-45ac-b739-44dfce0625d8"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "ir",
      "display_name": "R",
      "language": "R"
    }
  }
}