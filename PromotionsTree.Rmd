---
title: "Predicting Demand from Markdowns and Promotions"
jupyter:
  kernelspec:
    display_name: R
    language: R
    name: ir
---

```{r echo=T, results='hide', message=F, warning=F}
options("scipen"=100, "digits"=4)

if(!require("rpart")) install.packages("rpart")
if(!require("rpart.plot")) install.packages("rpart.plot")
if(!require("Metrics")) install.packages("Metrics")

library("rpart")
library("rpart.plot")
library("Metrics")
```

## Building the Regression Tree Model 


First lets take a look at the data we will work with. Suppose we have the following data from 15 months of demand for some product and want to predict the demand based on whether there was a markdown or not and also whether or not there was a promotion.

So here is the data we have, this will be our training data:

| markdown | promotion | demand |
|----------|-----------|--------|
| yes      | yes       | 74     |
| no       | no        | 23     |
| yes      | yes       | 61     |
| yes      | yes       | 59     |
| no       | no        | 25     |
| yes      | yes       | 63     |
| no       | yes       | 54     |
| yes      | no        | 42     |
| no       | yes       | 55     |
| yes      | yes       | 75     |
| no       | no        | 13     |
| yes      | yes       | 73     |
| yes      | no        | 31     |
| no       | no        | 12     |
| no       | no        | 11     |

- `demand` is our result or outcome
- `markdown` (true or false), `promotion` (true or false) are the predictors

We hope that these predictors will help up predict the `demand`.

To start we read the training data above from a csv file and print out its structore:

```{r}
trainurl<-"https://docs.google.com/spreadsheets/d/e/2PACX-1vTT6LcnhxE-mij5m5HHdLZ77YB1_teFiPUrM2uyafkGMUHs-zSKgylLnvgEOleRCB6jatqV1JjAczkp/pub?gid=0&single=true&output=csv"
traindf<-read.csv(trainurl, stringsAsFactors=TRUE)
str(traindf)
```
Let's print out the training set to make sure it looks like what we expect:

```{r}
print(traindf)
```

We will try to understand how to build up a decision tree for this example by just using one variable at a time to model the decision tree. 

### Splitting on Promotion 

First lets take a look at a simple model that uses just `promotion` to try to predict `demand`. 

So we are ready to see the predictions in each leaf node:

```{r}
control <- rpart.control(minbucket=1, maxdepth=1)
model1 <- rpart(demand~promotion, data=traindf, method="anova", control=control)
rpart.plot(model1, type=4, extra=101)
```

Notice that the prediction in each leaf node is just the mean over the rows that wind up in that leaf node.

### Splitting on Markdown 

Next lets look at a model that uses just `markdown` to try to predict `demand`:

```{r}
control <- rpart.control(minbucket=1, maxdepth=1)
model2 <- rpart(demand~markdown, data=traindf, method="anova", control=control)
rpart.plot(model2, type=4, extra=101)
```

### Regression Tree built using both `markdown` and `promotion`  

What about if we use both `promotion` and `markdown` together to predict `demand`: 

```{r}
control <- rpart.control(minbucket=1)
model3 <- rpart(demand~markdown+promotion, data=traindf, method="anova", control=control)
rpart.plot(model3, type=4, extra=101)
```

## Testing the Regression Tree 

Next let's look at some data that we can use as a testing set. This data we will use to evaluate how well the models we looked at above will do when they see "new" data. This gives a better idea of how accurate our model is.   So here is the data we will use as our testing data:     

First we read the test set and look at its structure:

```{r}
testurl<-"https://docs.google.com/spreadsheets/d/e/2PACX-1vTT6LcnhxE-mij5m5HHdLZ77YB1_teFiPUrM2uyafkGMUHs-zSKgylLnvgEOleRCB6jatqV1JjAczkp/pub?gid=1414619388&single=true&output=csv"
testdf<-read.csv(testurl, stringsAsFactors=TRUE)
str(testdf)
```

And now print out the test set:

```{r}
print(testdf)
```

### Testing `demand~promotion`

Here is the actual and the predicted for model1: 

```{r}
pred <- predict(model1, newdata = testdf)
comparedf <- data.frame(actual=testdf$demand, predictions=pred) 
print(comparedf)
```

Here is the MAPE, MAE and RMSE for model1:

```{r}
mape(testdf$demand, pred)
mae(testdf$demand, pred)
rmse(testdf$demand, pred)
```

### Testing `demand~markdown`

Here is the actual and the predicted for model2: 

```{r}
pred <- predict(model2, newdata = testdf)
comparedf <- data.frame(actual=testdf$demand, predictions=pred)
print(comparedf)
```

Here is the MAPE, MAE and RMSE for model2:

```{r}
mape(testdf$demand, pred)
mae(testdf$demand, pred)
rmse(testdf$demand, pred)
```

### Testing `demand~markdown+promotion`

Now we are ready to do some predictions using the test dataframe:

```{r}
pred <- predict(model3, newdata = testdf)
str(pred)
```

So `pred` now holds our predictions.

We can now compare those predictions (from our model) with the actual known results from the testing data. Here we are comparing how our model "predicted" on the test data with the "actual" outcomes that were included in the testing data. Here it is important that we know the actual outcomes on the testing data so we can see how we do. 

Lets make a data frame that shows the prediction and the actuals: 

```{r}
comparedf <- data.frame(actual=testdf$demand, predictions=pred)
print(comparedf)
```

Here is the MAPE, MAE and RMSE for our best model (model3):

```{r}
mape(testdf$demand, pred)
mae(testdf$demand, pred)
rmse(testdf$demand, pred)
```

