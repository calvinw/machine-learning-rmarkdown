{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (!require(\"Metrics\")) install.packages(\"Metrics\")\n",
    "library(\"Metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to look at ways to measure how far off the predictions from our\n",
    "models are from our actuals. One reason we need to do this is that we\n",
    "want to be able to determine what the best model is in machine learning\n",
    "or predictive analtics. When there are several different models\n",
    "possible, which one is the best? This boils down to the one that has the\n",
    "smallest error when run and tested using the testing data set.\n",
    "\n",
    "Remember the training data set you use when making the model, but then\n",
    "you test the model using the testing data set. When you test it, you\n",
    "measure its accuracy using one of the calculations below, depending on\n",
    "the kind of model it is and what you are trying to predict.\n",
    "\n",
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "Lets find the mean absolute error (MAE) for a prediction and some\n",
    "actuals. This is useful if your prediction is a quantity, like in simple\n",
    "or multiple regression, or for predicting a time series (data where time\n",
    "is the horizontal axis), or some other numerical value:\n",
    "\n",
    "Lets look at an example. Assume we have a model that we have already\n",
    "made some predictions and now we want to judge how good the predictions\n",
    "are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions <- c(12,23,32,15,22)\n",
    "actuals <- c(11,27,30,13,25)\n",
    "compare<-data.frame(actuals=actuals,\n",
    "                    predictions=predictions)\n",
    "compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the function `mae` from the Metrics package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae(actuals, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us the average error we make by using our model to predict\n",
    "with.\n",
    "\n",
    "Here are the details of this calculation by hand so you can see where it\n",
    "comes from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absError <- abs(predictions - actuals)\n",
    "info<-data.frame(actuals=actuals,\n",
    "                 predictions=predictions,\n",
    "                 absError=absError)\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take the mean of the absolute errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(absError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Percentage Error (MAPE)\n",
    "\n",
    "Next letâ€™s find the mean absolute percentage error (MAPE) for a\n",
    "prediction and some actuals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape(actuals, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absDeviation <- abs(predictions - actuals)\n",
    "percentErr<-absDeviation/actuals\n",
    "info<-data.frame(actuals=actuals,\n",
    "                 predictions=predictions,\n",
    "                 absDeviation=absDeviation,\n",
    "                 percentErr=round(percentErr,4)\n",
    "                 )\n",
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take the mean of the percentage errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(percentErr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us on average how far off percentage wise the prediction is\n",
    "from the actual (using the actual as base)"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "name": "ir",
   "display_name": "R",
   "language": "R"
  }
 }
}

