{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Accuracy"
      ],
      "id": "0f9f8715-8a96-407a-b067-c13dbeab9ace"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (!require(\"Metrics\")) install.packages(\"Metrics\")\n",
        "library(\"Metrics\")"
      ],
      "id": "4c9e0673-b05f-4fe3-9101-742c945058e6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose we had a machine learning model, which was predicting a\n",
        "categorical result like `yes` or `no` based on some predictors.\n",
        "\n",
        "Here is an example where we are predicting `Purchased` based on `Salary`\n",
        "and `Age`. Suppose we started with this **actual** data:\n",
        "\n",
        "#### Actual Observed Data\n",
        "\n",
        "| Salary | Age | Purchased |\n",
        "|--------|-----|-----------|\n",
        "| 53900  | 45  | yes       |\n",
        "| 50000  | 32  | no        |\n",
        "| 55900  | 57  | yes       |\n",
        "| 55600  | 29  | yes       |\n",
        "\n",
        "This means we know for sure that there was someone with `53900` salary\n",
        "and who was `45` and they did purchase whatever we are interested in\n",
        "here.\n",
        "\n",
        "Suppose we came up with a model, that made predictions of this data.\n",
        "\n",
        "And suppose this model made predictions like these:\n",
        "\n",
        "#### Model Predictions\n",
        "\n",
        "| Salary | Age | Prediction |\n",
        "|--------|-----|------------|\n",
        "| 53900  | 45  | no         |\n",
        "| 50000  | 32  | no         |\n",
        "| 55900  | 57  | yes        |\n",
        "| 55600  | 29  | yes        |\n",
        "\n",
        "We are interested how accurate our model is on this data.\n",
        "\n",
        "So for our predictions, how many of them did we get wrong?\n",
        "\n",
        "## Accuracy of Predictions\n",
        "\n",
        "Suppose we have some actuals and predicted to compare."
      ],
      "id": "51f888e3-4bc0-4ecd-9e7c-2b97ff01b3c0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  actuals predicted\n",
            "1     yes        no\n",
            "2      no        no\n",
            "3     yes       yes\n",
            "4     yes       yes"
          ]
        }
      ],
      "source": [
        "actuals   <- c(\"yes\", \"no\", \"yes\", \"yes\")\n",
        "predicted   <- c(\"no\", \"no\", \"yes\", \"yes\")\n",
        "df<- data.frame(actuals, predicted)\n",
        "print(df)"
      ],
      "id": "46cad560-a51e-4c10-95ee-9b78a8da270b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculating Accuracy\n",
        "\n",
        "We can find the accuracy from this table as follows:\n",
        "\n",
        "We calculate the proportion of agreement. This is called the\n",
        "**accuracy** of the model. The formula is just this:\n",
        "\n",
        "$$accuracy = \\frac{\\text{number of correct predictions}}{\\text{number of all predictions}}$$"
      ],
      "id": "dde91e03-3c5c-4c70-9751-686a5716187b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 0.75"
          ]
        }
      ],
      "source": [
        "accuracy(actuals, predicted)"
      ],
      "id": "7e7be335-d60a-4dce-9f7a-b753b4b85e51"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion Matrix\n",
        "\n",
        "Terminology:\n",
        "\n",
        "The prediction is called **positive** or **negative**:\n",
        "\n",
        "-   When the **prediction** is **yes** that is called a **positive**.\n",
        "-   When the **prediction** is **no** that is called a **negative**.\n",
        "\n",
        "The prediction is correct or incorrect:\n",
        "\n",
        "-   **true** means the prediction was correct\n",
        "-   **false** means the prediction was incorrect\n",
        "\n",
        "| Prediction Correct? | Prediction           |\n",
        "|---------------------|----------------------|\n",
        "| True or False       | Positive or Negative |\n",
        "\n",
        "So we have *true positive*, *false positive*, *true negative*, and\n",
        "*false negative*\n",
        "\n",
        "-   $TP$ prediction was yes, actual was yes\n",
        "-   $FP$ prediction was yes, actual was no\n",
        "-   $TN$ prediction was no, actual was no\n",
        "-   $FN$ prediction was no, actual was yes\n",
        "\n",
        "We can print out the confusion matrix like this:"
      ],
      "id": "3f65b296-4c32-4629-aff0-4a1097f503f2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       predicted\n",
            "actuals no yes\n",
            "    no   1   0\n",
            "    yes  1   2"
          ]
        }
      ],
      "source": [
        "table(actuals, predicted)"
      ],
      "id": "a5a4fe4c-9d39-4324-be19-5b00079f11a7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix\n",
        "\n",
        "|            |            | **Predicted** |            |\n",
        "|------------|------------|---------------|------------|\n",
        "|            |            | *Negative*    | *Positive* |\n",
        "| **Actual** | *Negative* | TN            | FP         |\n",
        "|            | *Positive* | FN            | TP         |\n",
        "\n",
        "Here are the results from the above:\n",
        "\n",
        "-   $TP$ prediction yes, actual yes - ??? times\n",
        "-   $FP$ prediction yes, actual no - ??? times\n",
        "-   $TN$ prediction no, actual no - ??? time\n",
        "-   $FN$ prediction no, actual yes - ??? time\n",
        "\n",
        "## Model 2"
      ],
      "id": "7df2f572-807a-44f7-ba32-2fa72090c1b7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  actuals predicted\n",
            "1     yes       yes\n",
            "2      no       yes\n",
            "3     yes       yes\n",
            "4     yes        no"
          ]
        }
      ],
      "source": [
        "actuals   <- c(\"yes\", \"no\", \"yes\", \"yes\")\n",
        "predicted   <- c(\"yes\", \"yes\", \"yes\", \"no\")\n",
        "df<- data.frame(actuals, predicted)\n",
        "df"
      ],
      "id": "82045ee0-19a7-4ac4-af77-c28ef719abfd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculating Accuracy"
      ],
      "id": "176c9be4-b7a2-4956-ad16-2d7edae5cb22"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] 0.5"
          ]
        }
      ],
      "source": [
        "accuracy(actuals, predicted)"
      ],
      "id": "fa0bbae0-aee5-4fcc-8460-c933f48fc6c2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Confusion Matrix"
      ],
      "id": "b8d6e1aa-9da0-4862-8fce-6281ba63c97a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       predicted\n",
            "actuals no yes\n",
            "    no   0   1\n",
            "    yes  1   2"
          ]
        }
      ],
      "source": [
        "table(actuals, predicted)"
      ],
      "id": "38dc2bab-f2f0-457d-b9d8-9851d2915608"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   $TP$ prediction yes, actual yes - ??? times\n",
        "-   $FP$ prediction yes, actual no - ??? times\n",
        "-   $TN$ prediction no, actual no - ??? time\n",
        "-   $FN$ prediction no, actual yes - ??? time\n",
        "\n",
        "Finally we can write the accuracy in terms of these:\n",
        "\n",
        "$$\n",
        "accuracy = \\frac{\\text{number of correct predictions}}{\\text{number of all predictions}} = \\frac{TP+TN}{TP+TN+FP+FN}\n",
        "$$\n",
        "\n",
        "### Similarities with Jury Trials and Hypothesis Testing\n",
        "\n",
        "|            |            | **Predicted** |            |\n",
        "|------------|------------|---------------|------------|\n",
        "|            |            | *Negative*    | *Positive* |\n",
        "| **Actual** | *Negative* | TN            | FP         |\n",
        "|            | *Positive* | FN            | TP         |\n",
        "\n",
        "Analogies:\n",
        "\n",
        "### Jury and Trials\n",
        "\n",
        "|            |            | **Jury**    |                 |\n",
        "|------------|------------|-------------|-----------------|\n",
        "|            |            | *Innocent*  | *Guilty*        |\n",
        "| **Actual** | *Innocent* | ok          | innocent jailed |\n",
        "|            | *Guilty*   | guilty free | ok              |\n",
        "\n",
        "### Hypothesis Testing (from Stat)\n",
        "\n",
        "|            |            | **Hyp Test of Null** |          |\n",
        "|------------|------------|----------------------|----------|\n",
        "|            |            | *accept*             | *reject* |\n",
        "| **Actual** | *true*     | ok                   | type 1   |\n",
        "|            | *not true* | type 2               | ok       |\n",
        "\n",
        "### Pregnancy Tests\n",
        "\n",
        "|            |       | **Pregnancy Test** |            |\n",
        "|------------|-------|--------------------|------------|\n",
        "|            |       | *no*               | *yes*      |\n",
        "| **Actual** | *no*  | test-, no          | test+, no  |\n",
        "|            | *yes* | test-, yes         | test+, yes |"
      ],
      "id": "ca8ff043-4288-4980-93d5-5f3c998e766c"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "ir",
      "display_name": "R",
      "language": "R"
    }
  }
}