{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (!require(\"Metrics\")) install.packages(\"Metrics\")\n",
    "library(\"Metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we had a machine learning model, which was predicting a result\n",
    "like `yes` or `no` based on some predictors.\n",
    "\n",
    "For example the data might be this:\n",
    "\n",
    "Model 1\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals   <- c(\"yes\", \"no\", \"yes\", \"yes\")\n",
    "predicted   <- c(\"yes\", \"no\", \"no\", \"yes\")\n",
    "df<- data.frame(actuals, predicted)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Accuracy\n",
    "\n",
    "We can find the accuracy from this table as follows:\n",
    "\n",
    "We calculate the proportion of agreement. This is called the\n",
    "**accuracy** of the model. The formula is just this:\n",
    "\n",
    "$$accuracy = \\frac{\\text{number of correct predictions}}{\\text{number of all predictions}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Terminology:\n",
    "\n",
    "The prediction is called **positive** or **negative**:\n",
    "\n",
    "-   When the **prediction** is **yes** that is called a **positive**.\n",
    "-   When the **prediction** is **no** that is called a **negative**.\n",
    "\n",
    "The prediction is correct or incorrect:\n",
    "\n",
    "-   **true** means the prediction was correct\n",
    "-   **false** means the prediction was incorrect\n",
    "\n",
    "So we have *true positive*, *false positive*, *true negative*, and\n",
    "*false negative*\n",
    "\n",
    "-   $TP$ prediction was yes, actual was yes\n",
    "-   $FP$ prediction was yes, actual was no\n",
    "-   $TN$ prediction was no, actual was no\n",
    "-   $FN$ prediction was no, actual was yes\n",
    "\n",
    "We can print out the confusion matrix like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the results from the above:\n",
    "\n",
    "-   $TP$ prediction yes, actual yes - 2 times\n",
    "-   $FP$ prediction yes, actual no - 0 times\n",
    "-   $TN$ prediction no, actual no - 1 time\n",
    "-   $FN$ prediction no, actual yes - 1 time\n",
    "\n",
    "Model 2\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals   <- c(\"no\", \"no\", \"yes\", \"yes\", \"no\", \"no\", \"yes\")\n",
    "predicted   <- c(\"yes\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\", \"yes\")\n",
    "df<- data.frame(actuals, predicted)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table(actuals, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   $TP$ prediction yes, actual yes - 2 times\n",
    "-   $FP$ prediction yes, actual no - 4 times\n",
    "-   $TN$ prediction no, actual no - 0 time\n",
    "-   $FN$ prediction no, actual yes - 1 time\n",
    "\n",
    "Finally we can write the accuracy in terms of these:\n",
    "\n",
    "$$\n",
    "accuracy = \\frac{\\text{number of correct predictions}}{\\text{number of all predictions}} = \\frac{TP+TN}{TP+FP+TN+FN}\n",
    "$$"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "name": "ir",
   "display_name": "R",
   "language": "R"
  }
 }
}
